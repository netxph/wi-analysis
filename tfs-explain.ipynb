{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Software Development Capability Analysis\n",
    "## by Marc Vitalis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Investigation Overview\n",
    "\n",
    "In this investigation we want to analyze the software development capability of our team. Capability is the amount of work that the team can deliver. The main focus is learning and improving the cycle time of each work item by dissecting the timestamps of the stages in the development, `new`, `doing` and `done`. Aside from that, we'll look at the `estimates` and how efficient it is in forecasting work.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset contains 5-year worth of workitems done at around ~1500 workitems. The team underwent 3 eras of software development methodologies: waterfall (Oct 2014 - May 2017), hybrid (June 2017 - July 2018), scrums (July 2018 - present). The attributes included are the timestamps of the 3 stages (`new`, `doing`, `done`), along with other descriptive information such as workitem type, the estimate, the resource assigned to and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pandas.plotting._converter as pandacnv\n",
    "from scipy.interpolate import spline\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# suppress warnings from final output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pandacnv.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# load in the dataset into a pandas dataframe\n",
    "workitems = pd.read_csv('workitems_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dates\n",
    "workitems.new = pd.to_datetime(workitems.new)\n",
    "workitems.doing = pd.to_datetime(workitems.doing)\n",
    "workitems.done = pd.to_datetime(workitems.done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change sprint to int\n",
    "workitems.loc[workitems.sprint.isna(), 'sprint'] = 0\n",
    "workitems.sprint = workitems.sprint.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitem_types = CategoricalDtype(categories = ['Story', 'Bug', 'Issue'], ordered=True)\n",
    "workitems.workitem_type = workitems.workitem_type.astype(workitem_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero sum should be converted to a day of work if they have worked on it at least 2h\n",
    "zero_work = workitems.actual_work == 0\n",
    "workitems.loc[zero_work, 'actual_work'] = 1\n",
    "\n",
    "#just remove the zero effort ones\n",
    "workitems = workitems[((workitems.done - workitems.doing) / pd.Timedelta(hours = 1)) >  2]\n",
    "#remove the time stamps in new, doing and done\n",
    "workitems.new = pd.to_datetime(workitems.new.dt.date)\n",
    "workitems.doing = pd.to_datetime(workitems.doing.dt.date)\n",
    "workitems.done = pd.to_datetime(workitems.done.dt.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extract the dates first\n",
    "workitems['doing_year'] = workitems.doing.dt.year\n",
    "workitems['done_year'] = workitems.done.dt.year\n",
    "workitems['new_year'] = workitems.new.dt.year\n",
    "\n",
    "workitems['doing_month'] = workitems.doing.dt.strftime('%b')\n",
    "workitems['done_month'] = workitems.done.dt.strftime('%b')\n",
    "workitems['new_month'] = workitems.new.dt.strftime('%b')\n",
    "\n",
    "workitems['doing_dow'] = workitems.doing.dt.strftime('%a')\n",
    "workitems['done_dow'] = workitems.done.dt.strftime('%a')\n",
    "workitems['new_dow'] = workitems.new.dt.strftime('%a')\n",
    "\n",
    "workitems['doing_my'] = workitems.doing.dt.strftime('%b %Y')\n",
    "workitems['done_my'] = workitems.done.dt.strftime('%b %Y')\n",
    "workitems['new_my'] = workitems.new.dt.strftime('%b %Y')\n",
    "\n",
    "weekdays_type = CategoricalDtype(categories=['Mon' , 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], ordered=True)\n",
    "months_type = CategoricalDtype(categories=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], ordered = True)\n",
    "my_type = CategoricalDtype(categories = pd.to_datetime(np.arange(workitems.new.min(), workitems.done.max() + pd.DateOffset(months = 1), 1, dtype='datetime64[M]')).strftime('%b %Y'), ordered = True)\n",
    "\n",
    "workitems.doing_month = workitems.doing_month.astype(months_type)\n",
    "workitems.done_month = workitems.done_month.astype(months_type)\n",
    "workitems.new_month = workitems.new_month.astype(months_type)\n",
    "\n",
    "workitems.doing_dow = workitems.doing_dow.astype(weekdays_type)\n",
    "workitems.done_dow = workitems.done_dow.astype(weekdays_type)\n",
    "workitems.new_dow = workitems.new_dow.astype(weekdays_type)\n",
    "\n",
    "workitems.new_my = workitems.new_my.astype(my_type)\n",
    "workitems.doing_my = workitems.doing_my.astype(my_type)\n",
    "workitems.done_my = workitems.done_my.astype(my_type)\n",
    "\n",
    "workitems['wi_weight'] = 0\n",
    "workitems.loc[workitems.workitem_type == 'Story', 'wi_weight'] = 2\n",
    "workitems.loc[workitems.workitem_type == 'Bug', 'wi_weight'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribution of Actual Work\n",
    "\n",
    "The unit of choice when calculating the actual work is by `Days`. The actual work is computed from the first time it's in doing stage and the first time it's in the done stage. To weed out workitems with no effort, there should be 2h interval between doing and done stage, then we treat that as one day worth of work effort.\n",
    "\n",
    "The actual work is in `logarithmic` view to properly look at values at the upper range with max of 94 days.\n",
    "\n",
    "Aside from huge number of workitems that can be done in a day, we can see a somehow steady distribution from 2 to 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "log_binsize = 0.05\n",
    "bins = 10 ** np.arange(0, np.log10(workitems['actual_work'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'actual_work', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([1, 2, 3, 5, 8, 13, 20, 40, 100], [1, 2, 3, 5, 8, 13, 20, 40, 100])\n",
    "plt.xlabel('Actual Work (Days)')\n",
    "plt.title('Distribution of Actual Work in Days')\n",
    "plt.grid(linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribution of Estimates\n",
    "\n",
    "Estimates are just points to describe the workitem size. It should imply that the bigger in size, it should take longer to do development. Most of the time we are using the poker estimation sequence `[1, 2, 3, 5, 8, 13, 20, 40, 100]`, which is somehow close to the fibonacci sequence. Estimates peaked at 8 points then gradually decrease in frequency in less or more than that.\n",
    "\n",
    "This graph also shows that we have varying story sizes, which may be more complex to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "log_binsize = 0.05\n",
    "bins = 10 ** np.arange(0, np.log10(workitems['estimate'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'estimate', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([1, 2, 3, 5, 8, 13, 20, 40, 100], [1, 2, 3, 5, 8, 13, 20, 40, 100])\n",
    "plt.xlabel('Estimates (Points)')\n",
    "plt.title('Distribution of Estimates')\n",
    "plt.grid(linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Actual Work vs Estimates\n",
    "\n",
    "At correlation value of 0.34, it's not enough to conclude that estimates is a good way to forecast amount of work the team can do on a certain period of time. However, our investigation shows that most of the data are within 1 - 20 days of work and 1 - 40 points of estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "g = sb.regplot(data = workitems, x = 'estimate', y = 'actual_work')\n",
    "ticks = [1, 2, 3, 5, 8, 13, 20, 40, 100]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks);\n",
    "plt.ylim([0, 40.5])\n",
    "plt.xlim([0, 40.5])\n",
    "plt.title('Actual Work vs Estimates')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('Estimate (Points)')\n",
    "plt.ylabel('Actual Work (Days)')\n",
    "g.text(25, 30, f'{workitems.actual_work.corr(workitems.estimate):.2f} corr', fontsize=24, fontweight='bold', color = 'Green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work Distribution\n",
    "\n",
    "We would like to see how the work is distributed per month. We can observe during waterfall era, it's hard to observe any pattern and there are tons of outliers in it. The hybrid era started May 2017, however, it underwent some ramp up time that we are starting to see its benefits 5 months later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = sb.color_palette()[0]\n",
    "\n",
    "plt.figure(figsize = (24, 16))\n",
    "plt.subplot(2, 1, 1)\n",
    "g = sb.countplot(data = workitems, x = 'done_my', hue = 'workitem_type');\n",
    "plt.legend(loc = 'upper right')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 30);\n",
    "plt.title('Work Distribution per Month')\n",
    "plt.grid(linestyle='--')\n",
    "plt.ylabel('Number of Workitems')\n",
    "plt.xlabel('')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "g = sb.boxplot(data = workitems, x = 'done_my', y = 'actual_work', color = base_color)\n",
    "plt.yticks([1, 5, 8, 13, 20, 40, 100]);\n",
    "plt.ylabel('Actual Work (Days)')\n",
    "plt.grid(linestyle='--')\n",
    "plt.xlabel('')\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability of the Main Developers\n",
    "As we can compare, waterfall era has huge gaps in developer's capability. This is a bit inconclusive as there's developers are working on workitems with no restrictions. In the latter era, we can see a better visual with developers' capability has closer gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "main_devs_old = workitems[(workitems.assigned_to.isin(['panuelk', 'delossj', 'tungald', 'bautise'])) & (workitems.era == 'waterfall')]\n",
    "sb.barplot(data = main_devs_old, x = 'assigned_to', y = 'actual_work', hue = 'workitem_type', ci = None)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Resource Capability - Waterfall Era')\n",
    "plt.ylabel('Actual Work (Days)')\n",
    "plt.xlabel('Main Developers')\n",
    "plt.grid(linestyle='--')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "main_devs_new = workitems[(workitems.assigned_to.isin(['panuelk', 'delossj', 'tungald', 'bautise'])) & (workitems.era != 'waterfall')]\n",
    "sb.barplot(data = main_devs_new, x = 'assigned_to', y = 'actual_work', hue = 'workitem_type', ci = None)\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Resource Capability - Hybrid and Scrums Era')\n",
    "plt.ylabel('')\n",
    "plt.xlabel('Main Developers')\n",
    "plt.grid(linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developers Capability Per Month\n",
    "\n",
    "As we can observe here, after a major spike in productivity, the developers are starting their capability on the latter part of software development. Lower value in capability the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cap = workitems[ \\\n",
    "    (workitems.assigned_to.isin(['panuelk', 'delossj', 'tungald', 'bautise'])) & \\\n",
    "    (workitems.era != 'waterfall') & (workitems.workitem_type != 'Issue') \\\n",
    "].groupby(['done_my', 'assigned_to']).agg({'actual_work': 'sum', 'wi_weight' : 'sum'}).reset_index()\n",
    "\n",
    "dev_cap['capability'] = dev_cap.actual_work / dev_cap.wi_weight\n",
    "\n",
    "plt.figure(figsize = (24, 10))\n",
    "g = sb.lineplot(data = dev_cap, x = 'done_my', y = 'capability', hue = 'assigned_to')\n",
    "plt.draw()\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 30);\n",
    "plt.title('Capability of Developers Per Month')\n",
    "plt.ylabel('Capability (Total Actual Work / Total Work Done)')\n",
    "plt.xlabel('');\n",
    "plt.grid(linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Capability Per Month\n",
    "\n",
    "After adjustments and humps, workitems starts to normalize in the latter part, flatlining on the last 4 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_actual_mean = workitems[workitems.era != 'waterfall'].groupby(['done_year', 'done_month', 'done_my', 'workitem_type']).actual_work.mean().reset_index()\n",
    "\n",
    "plt.figure(figsize = (24, 12))\n",
    "plt.subplot(2, 1, 1)\n",
    "g = sb.lineplot(data = work_actual_mean, x = 'done_my', y = 'actual_work', hue = 'workitem_type')\n",
    "plt.yticks([1, 3, 5, 8, 13, 20, 40, 50]);\n",
    "plt.title('Team Capability per Month')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Average Actual Work (Days)')\n",
    "plt.draw()\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 30)\n",
    "plt.grid(linestyle='--')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "team_cap = workitems[(workitems.era != 'waterfall') & (workitems.workitem_type != 'Issue')].groupby('done_my').agg({'actual_work': 'sum', 'wi_weight' : 'sum'}).reset_index()\n",
    "team_cap.loc[team_cap.wi_weight != 0, 'capability'] = team_cap.actual_work / team_cap.wi_weight\n",
    "g = sb.lineplot(data = team_cap, x = 'done_my', y = 'capability')\n",
    "plt.draw()\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation = 30)\n",
    "plt.title('Team Capability per Month - Combined')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Capability')\n",
    "plt.grid(linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> Once you're ready to finish your presentation, check your output by using\n",
    "nbconvert to export the notebook and set up a server for the slides. From the\n",
    "terminal or command line, use the following expression:\n",
    "> > `jupyter nbconvert <file_name>.ipynb --to slides --post serve --template output_toggle`\n",
    "\n",
    "> This should open a tab in your web browser where you can scroll through your\n",
    "presentation. Sub-slides can be accessed by pressing 'down' when viewing its parent\n",
    "slide. Make sure you remove all of the quote-formatted guide notes like this one\n",
    "before you finish your presentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
