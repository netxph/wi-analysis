{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software Development Capability Analysis\n",
    "## by Marc Vitalis\n",
    "\n",
    "## Preliminary Wrangling\n",
    "\n",
    "> Briefly introduce your dataset here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages and set plots to be embedded inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import pandas.plotting._converter as pandacnv\n",
    "\n",
    "%matplotlib inline\n",
    "pandacnv.register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load in your dataset and describe its properties through the questions below.\n",
    "Try and motivate your exploration goals through this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems = pd.read_csv('workitems_master.csv')\n",
    "workitems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Dates to Date type**\n",
    "\n",
    "Date format are represented as string (object), we should change them first to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.new = pd.to_datetime(workitems.new)\n",
    "workitems.doing = pd.to_datetime(workitems.doing)\n",
    "workitems.done = pd.to_datetime(workitems.done)\n",
    "\n",
    "workitems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Releases to Numeric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.loc[workitems.sprint.isna(), 'sprint'] = 0\n",
    "workitems.sprint = workitems.sprint.astype(int)\n",
    "workitems.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Category Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.workitem_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitem_types = CategoricalDtype(categories = ['Story', 'Bug', 'Issue'], ordered=True)\n",
    "workitems.workitem_type = workitems.workitem_type.astype(workitem_types)\n",
    "workitems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the structure of your dataset?\n",
    "\n",
    "> The dataset consists of 2393, with 10 features (workitem_type, estimate, words, rel (release), sprint, assigned_to, new (date started), doing (date started working), done, and actual work (done - doing). Variables main point of interest are the date stamps for the work. Some are just to describe the work item such as sprint, release and assigned_to.\n",
    "\n",
    "### What is/are the main feature(s) of interest in your dataset?\n",
    "\n",
    "> I'm more interested how variables affects `actual_work`. The goal is find out for the patterns that affects the actual work.\n",
    "\n",
    "### What features in the dataset do you think will help support your investigation into your feature(s) of interest?\n",
    "\n",
    "> The dataset contains data and underwent to three (3) SDLC pattern (non-structured, semi-agile, scrum). The date stamps are very important (`new`, `doing`, `done`), this will help me extract important information, such as days of the week, months, or observe the time flow pattern if the SDLC pattern improves through time, or made it worst. As bonus I can also make use the correlation of titles to the actual work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Exploration\n",
    "\n",
    "> First to explore is the main point of interest, `actual_work`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 1\n",
    "bins = np.arange(0, workitems.actual_work.max()+binsize, binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'actual_work', bins = bins)\n",
    "plt.xlabel('Actual Work (Days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a huge spike on the 0-1 area, it's unlikely to have a workitem with zero day done, that is considered as no effort. Let's tidy this a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero sum should be converted to a day of work if they have worked on it at least 2h\n",
    "zero_work = workitems.actual_work == 0\n",
    "workitems.loc[zero_work, 'actual_work'] = 1\n",
    "\n",
    "#just remove the zero effort ones\n",
    "workitems = workitems[((workitems.done - workitems.doing) / pd.Timedelta(hours = 1)) >  2]\n",
    "#remove the time stamps in new, doing and done\n",
    "workitems.new = pd.to_datetime(workitems.new.dt.date)\n",
    "workitems.doing = pd.to_datetime(workitems.doing.dt.date)\n",
    "workitems.done = pd.to_datetime(workitems.done.dt.date)\n",
    "\n",
    "workitems.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'actual_work', bins = bins)\n",
    "plt.xlabel('Actual Work (Days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still a huge spike in 1, and have a very long tail, let's redistribute it with log scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try log scale since it has a long tail\n",
    "log_binsize = 0.05\n",
    "bins = 10 ** np.arange(0, np.log10(workitems['actual_work'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'actual_work', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([2, 5, 8, 13, 20, 40, 50, 100, 200], [2, 5, 8, 13, 20, 40, 50, 100])\n",
    "plt.xlabel('Actual Work (Days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a big spike at one day work, and another clump in `20` days, somehow even distribution from `2-20`. On the later sprints, the team is now doing a 3 week scrum, which is somehow the same to 20 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems unusual to have work items that's take more than 30 days. Also, there's a big value on workitems th Let's try to find out if they are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to look at are the ones with value `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get items with actual_work = 1, and investigate the data\n",
    "ones = workitems[workitems.actual_work == 1]\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones.workitem_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By visual investigation, most of the workitems with `actual_work == 1` are mostly bugs. Now this make sense as bugs usually are quick to fix. Let's get their actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's investigate those workitems with more than 30 days value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems[workitems.actual_work > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items here are either from our work when we are still doing `waterfall`, or the newer ones, they are legitimate workitems that got back and forth in development, and some went to hiatus, and still they are valid data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[workitems.actual_work.mean(), workitems.actual_work.median(), workitems.actual_work.mode()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different data here. Mean, says a workitem can be done 9 days, average. This is hardly conclusive as we have work items that's pulling the value up. Median however, makes a bit more sense as a normal workitem is normally done 5 days. 1 has more occurrence, but since this data is not categorical, it just provides a bit of information about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based from the information gathered from the team, one day of work are mostly possible for what they call `Bug Fest`. More exploring on the relationship of the `actual_work` and `workitem_type`. For now, let's investigate the distribution of the `workitem_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_color = sb.color_palette()[0]\n",
    "sb.countplot(data = workitems, x = 'workitem_type', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a big number of bugs in comparison to stories. Which makes sense for the spike in 1 day `actual_work` in the data. Let's explore the data further by looking into number of workitems being worked on per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's extract the dates first\n",
    "workitems['doing_year'] = workitems.doing.dt.year\n",
    "workitems['done_year'] = workitems.done.dt.year\n",
    "workitems['new_year'] = workitems.new.dt.year\n",
    "\n",
    "workitems['doing_month'] = workitems.doing.dt.strftime('%b')\n",
    "workitems['done_month'] = workitems.done.dt.strftime('%b')\n",
    "workitems['new_month'] = workitems.new.dt.strftime('%b')\n",
    "\n",
    "workitems['doing_dow'] = workitems.doing.dt.strftime('%a')\n",
    "workitems['done_dow'] = workitems.done.dt.strftime('%a')\n",
    "workitems['new_dow'] = workitems.new.dt.strftime('%a')\n",
    "\n",
    "workitems['doing_my'] = workitems.doing.dt.strftime('%b %Y')\n",
    "workitems['done_my'] = workitems.done.dt.strftime('%b %Y')\n",
    "workitems['new_my'] = workitems.new.dt.strftime('%b %Y')\n",
    "\n",
    "weekdays_type = CategoricalDtype(categories=['Mon' , 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'], ordered=True)\n",
    "months_type = CategoricalDtype(categories=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], ordered=True)\n",
    "\n",
    "workitems.doing_month = workitems.doing_month.astype(months_type)\n",
    "workitems.done_month = workitems.done_month.astype(months_type)\n",
    "workitems.new_month = workitems.new_month.astype(months_type)\n",
    "\n",
    "workitems.doing_dow = workitems.doing_dow.astype(weekdays_type)\n",
    "workitems.done_dow = workitems.done_dow.astype(weekdays_type)\n",
    "workitems.new_dow = workitems.new_dow.astype(weekdays_type)\n",
    "\n",
    "workitems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_month = workitems.sort_values(['doing'])\n",
    "work_month['month'] = work_month.doing.dt.strftime('%b %Y')\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "sb.countplot(data = work_month, y = 'month', color = base_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_month = workitems.sort_values(['done'])\n",
    "work_month['month'] = work_month.done.dt.strftime('%b %Y')\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "sb.countplot(data = work_month, y = 'month', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the date has become more recent, it's getting more consistent on the number of workitems. We don't know yet the distribution of how many of these are stories, bugs or issues. More on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With scrums, there's a normal trend that during Fridays, there's a spike of things suddenly getting done. Let's investigate the distribution on weekdays, both on `doing` and `done`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "work_wk_doing = workitems\n",
    "\n",
    "work_wk_doing['week'] = workitems.doing.dt.strftime('%a').astype(weekdays_type)\n",
    "\n",
    "sb.countplot(data = work_wk_doing, x = 'week', color = base_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_wk_done = workitems\n",
    "\n",
    "work_wk_done['week'] = workitems.done.dt.strftime('%a').astype(weekdays_type)\n",
    "\n",
    "sb.countplot(data = work_wk_done, x = 'week', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the team is more productive when fresh during `Mondays`, finishing most items on `Tuesdays` and tends to slow down throughout the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next we'll look at is the distribution for product when creating new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea_month = workitems.sort_values(['new'])\n",
    "idea_month['month'] = idea_month.new.dt.strftime('%b %Y')\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "sb.countplot(data = idea_month, y = 'month', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 occurences when stories are created in bulk, `April 2015`, `May - Oct 2016` and `Dec 2017`. These are interesting points to ask what happened during these events. Let's check which day of the week normally the Product Team mostly creates stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_wk_idea = workitems\n",
    "\n",
    "work_wk_idea['week'] = workitems.new.dt.strftime('%a').astype(weekdays_type)\n",
    "\n",
    "sb.countplot(data = work_wk_idea, x = 'week', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a balance on when they add stories in the whole week, of course `Saturdays` and `Sundays` are holidays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the workitems per sprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO remove nan in sprint and change to int\n",
    "work_sprint = workitems\n",
    "work_sprint.loc[work_sprint.rel.isna(), 'rel'] = '0'\n",
    "work_sprint = work_sprint.sort_values(['rel', 'sprint'])\n",
    "\n",
    "work_sprint['rel_sprint'] = work_sprint.rel + '/' + work_sprint.sprint.astype(str).str.pad(width = 3, side = 'left', fillchar = '0')\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "sb.countplot(data = work_sprint, y = 'rel_sprint', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work items in each releases vary. Although there are items that slotted in Sprint zero which means there might be error in input on those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to investigate is the estimates provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binsize = 4\n",
    "bins = np.arange(0, workitems.estimate.max()+binsize, binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'estimate', bins = bins)\n",
    "plt.xlabel('Points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it has a long tail. Let's try plotting the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try log scale since it has a long tail\n",
    "log_binsize = 0.1\n",
    "bins = 10 ** np.arange(0, np.log10(workitems['estimate'].max())+log_binsize, log_binsize)\n",
    "\n",
    "plt.figure(figsize=[8, 5])\n",
    "plt.hist(data = workitems, x = 'estimate', bins = bins)\n",
    "plt.xscale('log')\n",
    "plt.xticks([2, 5, 8, 13, 20, 40, 50, 100, 200], [2, 5, 8, 13, 20, 40, 50, 100, 200])\n",
    "plt.xlabel('points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution has its peak between 8 to 13 estimates. Based on my conversation with the team, this is the 'just enough' size of stories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last to explore are the title broken down into words. Let's find out the top 40 word occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_words = workitems[['id', 'words']]\n",
    "\n",
    "work_words = work_words[['id', 'words']].words.str.split(',').apply(pd.Series) \\\n",
    "    .merge(work_words[['id', 'words']], right_index = True, left_index = True) \\\n",
    "    .drop([\"words\"], axis = 1) \\\n",
    "    .melt(id_vars = ['id'], value_name = \"word\") \\\n",
    "    .drop(\"variable\", axis = 1) \\\n",
    "    .dropna()\n",
    "\n",
    "plt.figure(figsize=(10, 15))\n",
    "sb.countplot(data = work_words, y = 'word', color = base_color, order = work_words.word.value_counts().iloc[:40].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results is interesting. Top entry is error, which probably evident mostly on bug items. Other items in top 40 mostly can describe the application itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the distribution worked per resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sb.countplot(data = workitems, y = 'assigned_to', color = base_color, order = workitems.assigned_to.value_counts().iloc[:40].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, find the distribution of workitems per era."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = workitems, x = 'era', color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the distribution(s) of your variable(s) of interest. Were there any unusual points? Did you need to perform any transformations?\n",
    "\n",
    "The actual work contains `zero` days which means `no effort`. I recalculated the actual effort by getting what's normally considered as work which is `2 hours`, and considered that already as one day of work. There are also what seems to be outliers, with high value in `one-day work`, however, with investigation, I found out that these are mostly bugs which makes sense as bugs are usually easy to get done. On the high spectrum, I checked them online the patterns on why they have large values. Some of them are from our waterfall method which consists of large `stories` and took days to months just to finished. Some of the data are also difficult to resolve which spanned to multiple sprints. I feel that they are important part of our data for now.\n",
    "\n",
    "### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?\n",
    "\n",
    "I recalculated `actual_work` to weed out the `no effort` stories. The words field are comma-delimited string, was converted into it's own data frame so we can examine them individually. To investigate individual characteristics of the dates, i also extracted `year`, `month` and `dow` of `new`, `doing` and `done`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Exploration\n",
    "\n",
    "First let's check pairwise correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = ['actual_work', 'estimate']\n",
    "categoric_vars = ['workitem_type', 'era', 'new_month', 'doing_month', 'done_month', 'new_dow', 'doing_dow', 'done_dow']\n",
    "\n",
    "work_est = workitems[~workitems.estimate.isna()]\n",
    "\n",
    "sb.heatmap(work_est[numeric_vars].corr(), annot = True, fmt = '.3f', cmap = 'vlag_r', center = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sb.PairGrid(data = work_est, vars = numeric_vars)\n",
    "g = g.map_diag(plt.hist, bins = 10)\n",
    "g.map_offdiag(plt.scatter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxgrid(x, y, **kwargs):\n",
    "    \"\"\" Quick hack for creating box plots with seaborn's PairGrid. \"\"\"\n",
    "    default_color = sb.color_palette()[0]\n",
    "    sb.boxplot(x, y, color = default_color)\n",
    "\n",
    "plt.figure(figsize = [10, 10])\n",
    "g = sb.PairGrid(data = work_est, y_vars = ['actual_work', 'estimate'], x_vars = categoric_vars,\n",
    "                height = 3, aspect = 1.5)\n",
    "g.map(boxgrid)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `actual_work` vs. `estimates`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this information, the correlation is somehow far from +1, which means that estimating has no not quite have any relation to actual work. Let's look closely on this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sb.regplot(data = work_est, x = 'estimate', y = 'actual_work')\n",
    "ticks = [1, 3, 5, 8, 13, 20, 40, 100]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation may conclude that estimates does not quite relate to the actual work done. However, looking closely at its scatter graph, estimates clump at estimate 1-13, and almost similarly, actual work clumps from 1 to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `actual_work` vs `workitem_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out if time to complete is similar across different work item types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(data = workitems, x = 'workitem_type', y = 'actual_work', color = base_color)\n",
    "plt.yticks([1, 3, 5, 8, 13, 20, 25]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may have outliers, let's have a different view with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.violinplot(data = workitems, x = 'workitem_type', y = 'actual_work', color = base_color)\n",
    "plt.yticks([1, 3, 5, 8, 13, 20, 40, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some outliers, let's try to look at the median instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(data = workitems, x = 'workitem_type', y = 'actual_work', color = base_color, estimator = np.median);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stories finish much longer than bugs and issues. Therefore we cannot have them counted in the same level when we are looking at number of workitems done on a certain period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `actual_work` vs `era`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of workitem types per era."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(data = workitems, x = 'era', y = 'actual_work', color = base_color);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.violinplot(data = workitems, x = 'era', y = 'actual_work', color = base_color);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Waterfall has the best cycle time, which odd. Let's find out more, by looking at the work item types per `era`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.countplot(data = workitems, x = 'era', hue = 'workitem_type', palette = 'Blues')\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this makes sense, bug fixing take shorter time to complete thus making waterfall era with the best cycle time. Also, we can notice here that during waterfall era, we produced a lot more bugs compared to the recent era."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `actual_work` per month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out patterns when we view actual_work per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (32, 12))\n",
    "g = sb.barplot(data = workitems, x = 'done_my', y = 'actual_work', color = base_color)\n",
    "g.set_xticklabels(workitems.done_my.unique(), rotation = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teams capability (average cycle time) has some stable line with some months with notable spikes. A boxplot might provide us some perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 24))\n",
    "sb.boxplot(data = workitems, y = 'done_my', x = 'actual_work', color = base_color)\n",
    "plt.xticks([1, 3, 5, 8, 13, 20, 40, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice some spikes and high value. We plot next the count per work item type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8, 24))\n",
    "sb.countplot(data = workitems.sort_values(['done_year', 'done_month']), y = 'done_my', hue = 'workitem_type', palette = 'Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discarding the months with sudden spike, recently workitems are completed in between 3 to 5 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `actual_work` vs. `assigned_to`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the distribution of workitems worked by the resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.barplot(data = workitems, y = 'assigned_to', x = 'actual_work', color = base_color, order = workitems.assigned_to.value_counts().index)\n",
    "plt.xticks([1, 3, 5, 8, 13, 20, 40]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sb.countplot(data = workitems, y = 'assigned_to', hue = 'workitem_type', palette = 'Blues', order = workitems.assigned_to.value_counts().index)\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that `panuelk` has worked on more items, most of it are of type bugs. `delossj` on the other hand has worked on more stories and issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### November 2017 and Later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed in the graph, number of work per month started to normalize from November 2017. Let's try to cut our dataset from there and create new graphs for observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems_scrums = workitems[workitems.done >= '2017-11-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_est = workitems_scrums[~workitems_scrums.estimate.isna()]\n",
    "\n",
    "sb.heatmap(work_est[numeric_vars].corr(), annot = True, fmt = '.3f', cmap = 'vlag_r', center = 0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sb.regplot(data = work_est, x = 'estimate', y = 'actual_work')\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(data = workitems_scrums, x = 'workitem_type', y = 'actual_work', color = base_color, estimator = np.median);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.violinplot(data = workitems_scrums, x = 'workitem_type', y = 'actual_work', color = base_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sb.countplot(data = workitems_scrums, y = 'assigned_to', hue = 'workitem_type', palette = 'Blues', order = workitems_scrums.assigned_to.value_counts().index)\n",
    "plt.legend(loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.barplot(data = workitems_scrums, y = 'assigned_to', x = 'actual_work', color = base_color, order = workitems_scrums.assigned_to.value_counts().index)\n",
    "plt.xticks([1, 3, 5, 8, 13, 20, 40]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provided a surprising insight, which may solve our estimation issue. The correlation is now very close to zero, which means, regardless how big or small we estimate, the actual work remains the same. The resources' capability on the other hand is a bit cleaner and almost on the same level with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `workitem_type` with weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract `workitem_type` weight for the workitems post November 2017 and find more insight with this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_median = workitems_scrums[workitems_scrums.workitem_type == 'Story'].actual_work.median()\n",
    "bug_median = workitems_scrums[workitems_scrums.workitem_type == 'Bug'].actual_work.median()\n",
    "\n",
    "story_weight = story_median / (story_median + bug_median)\n",
    "bug_weight = bug_median / (story_median + bug_median)\n",
    "\n",
    "story_weight, bug_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workitems_scrums.loc[workitems_scrums.workitem_type == 'Bug', 'wi_weight'] = bug_weight\n",
    "workitems_scrums.loc[workitems_scrums.workitem_type == 'Story', 'wi_weight'] = story_weight\n",
    "\n",
    "workitems_scrums.wi_weight.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.barplot(data = workitems_scrums.sort_values(['done_year', 'done_month']), x = 'wi_weight', y = 'done_my', estimator = np.sum, color = base_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.barplot(data = workitems_scrums, x = 'wi_weight', y = 'assigned_to', estimator = np.sum, color = base_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the weight gives us more accurate view as to the amount of work done per month and per resource. Interestingly enough we did not find any pattern as the graph shows that every month, not the same amount of work is distributed to the team. This maybe due to poor estimation which resulted to uneven work amount per month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?\n",
    "\n",
    "Estimation is an integral part of software development. It helps stakeholders forecast when the project is going to completed, and how many items should be committed to work on a certain timeframe. After comparing the estimates with the actual work, we found out that the estimation activity done by the team has low correlation to the actual work done. With this we may need to find ways to improve how estimation should be done to the team. We may find out more insight when we compare more variables at once. \n",
    "\n",
    "Another interesting observation is how work item types relates to the actual work done. Stories took much longer to finish than bugs and issues. Given this information, it's hard to determine the teams capability with work items with different weight are being worked on a certain timeframe.\n",
    "\n",
    "We also measured capability (average cycle time) of each resource, the main developers (panuelk, delossj, tungald, bautise) are almost on the same capability rating except deguzmm, which makes sense because she is their lead which has other things on her plate that delays finishing her work items.\n",
    "\n",
    "After cutting the data from November 2017 onwards, we found more interesting patterns with the data. Correlation between estimate and actual work now very close to zero, meaning, even how much estimate we do, the actual days of work almost stays the same. This gives proof that we might better end up implementing counting of stories/bugs rather than estimates.\n",
    "\n",
    "### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?\n",
    "\n",
    "The team underwent three major changes in software development style (era). Number of workitems done in a month varies a lot during waterfall era, which makes this analysis more challenging. As we observed above, the number of items being worked on started to stabilize starting November 2017, 6 months after we transition from waterfall to hybrid.\n",
    "\n",
    "Also, interesting observation, during early stage (waterfall), software development produced a lot more bugs than on hybrid and scrum era, which can delay the productivity of the team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Exploration\n",
    "\n",
    "> answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual and Estimation Reinforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.scatterplot(data = workitems_scrums, x = 'estimate', y = 'actual_work', hue = 'workitem_type', alpha = 0.4)\n",
    "ticks = [1, 3, 5, 8, 13, 20, 40, 100]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.scatterplot(data = workitems, x = 'estimate', y = 'actual_work', hue = 'workitem_type', alpha = 0.4)\n",
    "ticks = [1, 3, 5, 8, 13, 20, 40, 100]\n",
    "plt.xticks(ticks)\n",
    "plt.yticks(ticks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_actual_mean = workitems_scrums.groupby(['done_year', 'done_month', 'done_my', 'workitem_type']).actual_work.mean().reset_index()\n",
    "\n",
    "plt.figure(figsize = (16, 4))\n",
    "g = sb.lineplot(data = work_actual_mean, x = 'done_my', y = 'actual_work', hue = 'workitem_type')\n",
    "g.set_xticklabels(work_actual_mean.done_my.unique(), rotation = 30);\n",
    "plt.yticks([1, 3, 5, 8, 13, 20, 40, 50]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "sb.barplot(data = workitems_scrums, x = 'assigned_to', y = 'actual_work', hue = 'workitem_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding out the sweet average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24, 24))\n",
    "plt.subplot(4, 1, 1)\n",
    "g = sb.barplot(data = workitems_scrums[workitems_scrums.assigned_to == 'panuelk'], x = 'done_my', y = 'actual_work', hue = 'workitem_type')\n",
    "g.set_xticklabels(work_actual_mean.done_my.unique());\n",
    "\n",
    "plt.subplot(4, 1, 2)\n",
    "g = sb.barplot(data = workitems_scrums[workitems_scrums.assigned_to == 'delossj'], x = 'done_my', y = 'actual_work', hue = 'workitem_type')\n",
    "g.set_xticklabels(work_actual_mean.done_my.unique());\n",
    "\n",
    "plt.subplot(4, 1, 3)\n",
    "g = sb.barplot(data = workitems_scrums[workitems_scrums.assigned_to == 'tungald'], x = 'done_my', y = 'actual_work', hue = 'workitem_type')\n",
    "g.set_xticklabels(work_actual_mean.done_my.unique());\n",
    "\n",
    "plt.subplot(4, 1, 4)\n",
    "g = sb.barplot(data = workitems_scrums[workitems_scrums.assigned_to == 'bautise'], x = 'done_my', y = 'actual_work', hue = 'workitem_type')\n",
    "g.set_xticklabels(work_actual_mean.done_my.unique());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_devs = workitems_scrums[workitems_scrums.assigned_to.isin(['panuelk', 'delossj', 'tungald', 'bautise'])]\n",
    "\n",
    "plt.figure(figsize = (24, 6))\n",
    "sb.barplot(data = main_devs, x = 'done_my', y = 'wi_weight', hue = 'assigned_to', estimator = np.sum)\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sums = main_devs.groupby(['done_year', 'done_month', 'done_my', 'assigned_to']).wi_weight.sum().reset_index()\n",
    "weight_sums = weight_sums.groupby(['done_year', 'done_month', 'done_my']).agg({'assigned_to': 'count', 'wi_weight': 'sum'}).reset_index()\n",
    "weight_sums['unit'] = weight_sums.wi_weight / weight_sums.assigned_to\n",
    "\n",
    "plt.figure(figsize = (24, 6))\n",
    "\n",
    "g = sb.barplot(data = weight_sums, x = 'done_my', y = 'unit', color = base_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24, 8))\n",
    "sb.scatterplot(data = workitems_scrums, x = 'doing', y = 'actual_work', hue = 'workitem_type')\n",
    "plt.xlim(pd.to_datetime('2017-11-01'), pd.to_datetime('2019-07-31'))\n",
    "plt.yticks([1, 3, 5, 8, 13, 20, 40, 100]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of work a developer can do in a month\n",
    "print(weight_sums.unit.mean())\n",
    "\n",
    "# average amount of days each work can be done\n",
    "print(main_devs.actual_work.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?\n",
    "\n",
    "> Your answer here!\n",
    "\n",
    "### Were there any interesting or surprising interactions between features?\n",
    "\n",
    "> Your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> At the end of your report, make sure that you export the notebook as an\n",
    "html file from the `File > Download as... > HTML` menu. Make sure you keep\n",
    "track of where the exported file goes, so you can put it in the same folder\n",
    "as this notebook for project submission. Also, make sure you remove all of\n",
    "the quote-formatted guide notes like this one before you finish your report!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create ratio between work item types\n",
    "* Create separate investigation between actual work, work item type, per month and era\n",
    "* Construct a mathematical formula that will compute the estimate capacity\n",
    "* Prove the better estimation by testing with current data and running correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
